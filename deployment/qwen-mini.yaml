# qwen-deployment-local-direct.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qwen-mini
spec:
  replicas: 1
  selector:
    matchLabels:
      app: qwen
  template:
    metadata:
      labels:
        app: qwen
    spec:
      containers:
        - name: text-generation
          image: ghcr.io/huggingface/text-generation-inference:1.4.1
          command: ["text-generation-launcher"]
          args:
            - "--model-id"
            - "/model"  # 关键修改：指向容器内的挂载路径
            - "--num-shard"
            - "1"
            - "--port"
            - "8000"
            - "--quantize"
            - "bitsandbytes"
          env:
            - name: TRANSFORMERS_OFFLINE  # 强制离线模式
              value: "1"
            - name: HF_HUB_OFFLINE  # 禁用 Hugging Face Hub 连接
              value: "1"
            - name: NVIDIA_DISABLE_REQUIRE
              value: "1"
          resources:
            limits:
              nvidia.com/microgpu: 1
          ports:
            - containerPort: 8000
          volumeMounts:
            - name: model-storage
              mountPath: /model  # 容器内访问路径
      volumes:
        - name: model-storage
          hostPath:
            path: /home/k8sadmin/Qwen1.5-0.5B-Chat  # 您本地的模型目录
            type: Directory  # 确保指定为目录类型
---
apiVersion: v1
kind: Service
metadata:
  name: qwen-service
spec:
  type: NodePort
  selector:
    app: qwen
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
      nodePort: 30080
