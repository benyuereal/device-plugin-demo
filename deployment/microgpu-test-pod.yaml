apiVersion: v1
kind: Pod
metadata:
  name: microgpu-test-pod
spec:
  restartPolicy: Never
  containers:
    - name: qwen-inference
      image: nvcr.io/nvidia/pytorch:24.05-py3
      command: ["sleep", "infinity"]
      resources:
        requests:
          nvidia.com/microgpu: 1
        limits:
          nvidia.com/microgpu: 1

      volumeMounts:
        - name: model-storage
          mountPath: /model
        # 仅挂载 NVIDIA 特定库文件，而不是整个目录
        - name: nvidia-libs
          mountPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so
          subPath: libnvidia-ml.so
        - name: nvidia-libs
          mountPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
          subPath: libnvidia-ml.so.1
        - name: nvidia-libs
          mountPath: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.550.127.08
          subPath: libnvidia-ml.so.550.127.08
  volumes:
    - name: model-storage
      hostPath:
        path: /home/Qwen1.5-0.5B-Chat
        type: Directory
#    - name: nvidia-bin
#      hostPath:
#        path: /usr/bin
#        type: Directory
    # 新增：宿主机库目录
    - name: nvidia-lib
      hostPath:
        path: /usr/lib/x86_64-linux-gnu
        type: Directory
#    - name: nvidia-lib64
#      hostPath:
#        path: /usr/lib64
#        type: Directory