apiVersion: v1
kind: Pod
metadata:
  name: microgpu-test-pod
spec:
  restartPolicy: Never  # 执行完成后不重启
  containers:
    - name: qwen-inference
      image: nvcr.io/nvidia/pytorch:24.05-py3
      command: ["sleep", "infinity"]  # 保持容器运行
      resources:
        requests:
          nvidia.com/microgpu: 1
        limits:
          nvidia.com/microgpu: 1
#      volumeMounts:
#        - name: model-storage
#          mountPath: /model
#        - name: cuda-lib
#          mountPath: /usr/local/nvidia/lib64
#  volumes:
#    - name: model-storage
#      hostPath:
#        path: /home/k8sadmin/Qwen1.5-0.5B-Chat
#        type: Directory
#    - name: cuda-lib
#      hostPath:
#        path: /usr/lib/x86_64-linux-gnu