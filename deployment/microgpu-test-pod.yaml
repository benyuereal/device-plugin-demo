apiVersion: v1
kind: Pod
metadata:
  name: microgpu-test-pod
spec:
  restartPolicy: Never
  runtimeClassName: nvidia  # Pod 中引用此 RuntimeClass
  containers:
    - name: qwen-inference
      image: nvcr.io/nvidia/pytorch:24.05-py3
      command: ["nvidia-smi"]  # 显式调用入口点
      args: ["sleep", "infinity"]
      resources:
        requests:
          nvidia.com/gpu: 1
        limits:
          nvidia.com/gpu: 1

      volumeMounts:
        - name: model-storage
          mountPath: /model

  volumes:
    - name: model-storage
      hostPath:
        path: /home/Qwen1.5-0.5B-Chat
        type: Directory
