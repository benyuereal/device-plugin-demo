apiVersion: v1
kind: Pod
metadata:
  name: microgpu-test-pod
spec:
  restartPolicy: Never
  containers:
    - name: qwen-inference
      image: nvcr.io/nvidia/pytorch:24.05-py3
      command: ["sleep", "infinity"]
      resources:
        requests:
          nvidia.com/microgpu: 1
        limits:
          nvidia.com/microgpu: 1
      env:
        # 确保包含所有可能的库路径
        - name: LD_LIBRARY_PATH
          value: /usr/lib/x86_64-linux-gnu:/usr/lib64:/usr/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:$LD_LIBRARY_PATH
      volumeMounts:
        - name: model-storage
          mountPath: /model
        - name: nvidia-bin
          mountPath: /usr/local/nvidia/bin
        # 新增：挂载宿主机库目录
        - name: nvidia-lib
          mountPath: /usr/lib/x86_64-linux-gnu
        - name: nvidia-lib64
          mountPath: /usr/lib64
  volumes:
    - name: model-storage
      hostPath:
        path: /home/Qwen1.5-0.5B-Chat
        type: Directory
    - name: nvidia-bin
      hostPath:
        path: /usr/bin
        type: Directory
    # 新增：宿主机库目录
    - name: nvidia-lib
      hostPath:
        path: /usr/lib/x86_64-linux-gnu
        type: Directory
    - name: nvidia-lib64
      hostPath:
        path: /usr/lib64
        type: Directory